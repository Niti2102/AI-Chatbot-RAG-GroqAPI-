from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings  # ‚úÖ updated import
from langchain_community.vectorstores import FAISS
from langchain_groq import ChatGroq
from langchain.chains import RetrievalQA
import streamlit as st
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# ‚úÖ FIXED: Set up embeddings using HuggingFace with meta tensor workaround
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2",
    model_kwargs={
        "device": "cpu",  # ‚¨ÖÔ∏è force CPU usage
        "trust_remote_code": True  # ‚¨ÖÔ∏è fixes meta tensor issue in torch 2.3+
    }
)

# Load the FAISS index
vectordb = FAISS.load_local("faissindex", embeddings, allow_dangerous_deserialization=True)

# Set up retriever and LLM (Groq + LLaMA 3)
retriever = vectordb.as_retriever()
llm = ChatGroq(
    groq_api_key=os.environ["GROQ_API_KEY"],
    model_name="llama3-70b-8192"
)

# Build the QA chain
chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)

# Streamlit UI setup
st.set_page_config(page_title="Nitish M AI Chatbot")
st.title("ü§ñ ASK ANYTHING FROM MY RESUME")

query = st.text_input("üîç Pinch your questions:")

if query:
    with st.spinner("ü§î Thinking..."):
        response = chain.invoke(query)  # ‚úÖ recommended over deprecated `.run()`
        st.success(response)
